name: Build Windows Executable

on:
  push:
    tags:
      - 'v*'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  build-windows:
    runs-on: windows-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pyinstaller

    - name: Build executable
      run: |
        pyinstaller --clean TranslateBook.spec

    - name: Get executable size
      id: exe_info
      shell: pwsh
      run: |
        $size = (Get-Item dist\TranslateBook.exe).Length
        $sizeMB = [math]::Round($size / 1MB, 2)
        echo "size_bytes=$size" >> $env:GITHUB_OUTPUT
        echo "size_mb=$sizeMB" >> $env:GITHUB_OUTPUT

    - name: Create release archive
      shell: pwsh
      run: |
        # Create a release folder with the executable and readme
        New-Item -ItemType Directory -Path release -Force
        Copy-Item dist\TranslateBook.exe release\

        # Create a simple README for the release
        $readme = @"
        # TranslateBook Windows Executable

        ## Quick Start

        1. Extract TranslateBook.exe to a folder of your choice
        2. Install Ollama from https://ollama.ai (required for local LLM)
        3. Download a translation model: ollama pull qwen3:14b
        4. Double-click TranslateBook.exe to start the server
        5. Open your browser to http://localhost:5000

        ## Choosing the Best Model for Your Language

        Different models perform better for different target languages!

        ðŸ“Š See our comprehensive benchmarks to find the best model for your target language:
        ðŸ‘‰ https://github.com/hydropix/TranslateBookWithLLM/wiki

        Benchmarks include 11 models tested across 19 languages with accuracy, fluency, and style scores.

        ## First Run

        On first run, the application will:
        - Create a TranslateBook_Data folder next to the executable
        - Generate a default .env configuration file
        - Create necessary subdirectories (translated_files, checkpoints)

        ## Configuration

        Edit TranslateBook_Data\.env to customize:
        - LLM provider (Ollama, OpenAI, Gemini, OpenRouter)
        - Model selection
        - API keys for cloud providers
        - Server port and host

        ## Usage

        - Web UI: http://localhost:5000
        - Supported formats: .txt, .epub, .srt
        - Output files: TranslateBook_Data\translated_files\

        ## Links

        - ðŸ“š Full Documentation: https://github.com/hydropix/TranslateBookWithLLM
        - ðŸ“Š Model Benchmarks: https://github.com/hydropix/TranslateBookWithLLM/wiki
        - ðŸ› Report Issues: https://github.com/hydropix/TranslateBookWithLLM/issues
        - ðŸŒ OpenRouter Models: https://openrouter.ai/models (200+ cloud models)
        "@

        $readme | Out-File -FilePath release\README.txt -Encoding UTF8

        # Create zip archive
        Compress-Archive -Path release\* -DestinationPath TranslateBook-Windows.zip

    - name: Upload artifact
      uses: actions/upload-artifact@v4
      with:
        name: TranslateBook-Windows
        path: TranslateBook-Windows.zip
        retention-days: 90

    - name: Upload executable only
      uses: actions/upload-artifact@v4
      with:
        name: TranslateBook.exe
        path: dist\TranslateBook.exe
        retention-days: 90

    - name: Build summary
      shell: pwsh
      run: |
        echo "### Build Complete! :rocket:" >> $env:GITHUB_STEP_SUMMARY
        echo "" >> $env:GITHUB_STEP_SUMMARY
        echo "**Executable Size:** ${{ steps.exe_info.outputs.size_mb }} MB" >> $env:GITHUB_STEP_SUMMARY
        echo "" >> $env:GITHUB_STEP_SUMMARY
        echo "**Artifacts:**" >> $env:GITHUB_STEP_SUMMARY
        echo "- TranslateBook-Windows.zip (executable + README)" >> $env:GITHUB_STEP_SUMMARY
        echo "- TranslateBook.exe (standalone)" >> $env:GITHUB_STEP_SUMMARY

    - name: Create Release (on tag)
      if: startsWith(github.ref, 'refs/tags/v')
      uses: softprops/action-gh-release@v1
      with:
        files: TranslateBook-Windows.zip
        body: |
          ## Windows Executable Release

          ### Installation
          1. Download and extract TranslateBook-Windows.zip
          2. Install [Ollama](https://ollama.ai) (required for local LLM)
          3. Run TranslateBook.exe
          4. Open http://localhost:5000 in your browser

          ### What's Included
          - Single-file Windows executable (no Python installation required)
          - Auto-generated configuration on first run
          - Support for .txt, .epub, .srt translation

          ### System Requirements
          - Windows 10/11 (64-bit)
          - Ollama installed for local LLM support
          - Or API keys for cloud providers (OpenAI, Gemini, OpenRouter)

          **Size:** ${{ steps.exe_info.outputs.size_mb }} MB
        draft: false
        prerelease: false
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
