# Translation API Configuration
API_ENDPOINT=http://localhost:11434/api/generate
DEFAULT_MODEL=mistral-small:24b
PORT=5000  # Port for the web interface

# LLM Provider Settings
LLM_PROVIDER=ollama  # Options: ollama, gemini, openai
GEMINI_API_KEY=  # Your Google Gemini API key (required if using gemini provider)
GEMINI_MODEL=gemini-2.0-flash  # Default Gemini model
OPENAI_API_KEY=  # Your OpenAI API key (required if using openai provider)

# Translation Settings
DEFAULT_SOURCE_LANGUAGE=English  # Default source language (can be any language name)
DEFAULT_TARGET_LANGUAGE=French  # Default target language (can be any language name)
MAIN_LINES_PER_CHUNK=25  # Target lines per chunk (may be auto-adjusted)
MAIN_CHUNK_SIZE=1000      # Maximum characters per chunk
REQUEST_TIMEOUT=900       # API timeout in seconds

# Context Management (IMPORTANT)
# Recommended: 8192 for chunk_size=25, 16384 for chunk_size=50
OLLAMA_NUM_CTX=8192

# Automatic Context Optimization
AUTO_ADJUST_CONTEXT=true  # Automatically adjust context/chunk size if prompt too large
MIN_CHUNK_SIZE=5          # Minimum lines per chunk when auto-adjusting
MAX_CHUNK_SIZE=100        # Maximum lines per chunk

# Advanced
MAX_TRANSLATION_ATTEMPTS=3
RETRY_DELAY_SECONDS=5

# SRT-specific configuration
SRT_LINES_PER_BLOCK=5
SRT_MAX_CHARS_PER_BLOCK=500