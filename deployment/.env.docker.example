# Docker Environment Configuration for TranslateBookWithLLM
# Copy this file to .env in the same directory as docker-compose.yml
# and configure according to your needs

# ============================================================================
# SERVER CONFIGURATION
# ============================================================================
PORT=5000
# Note: HOST is automatically set to 0.0.0.0 inside the container

# ============================================================================
# LLM PROVIDER SELECTION
# ============================================================================
# Options: ollama, gemini, openai
LLM_PROVIDER=ollama

# ============================================================================
# OLLAMA CONFIGURATION (if LLM_PROVIDER=ollama)
# ============================================================================
# For Docker on Windows/Mac: use host.docker.internal to access host machine
# For Docker on Linux: uncomment extra_hosts in docker-compose.yml OR use host IP
API_ENDPOINT=http://host.docker.internal:11434/api/generate

# Model to use (must be installed in your local Ollama)
DEFAULT_MODEL=mistral-small:24b

# Context window size (8192 recommended for chunk_size=25)
OLLAMA_NUM_CTX=8192

# ============================================================================
# GEMINI CONFIGURATION (if LLM_PROVIDER=gemini)
# ============================================================================
# Uncomment and set your API key if using Gemini
# GEMINI_API_KEY=your_gemini_api_key_here
# GEMINI_MODEL=gemini-2.0-flash

# ============================================================================
# OPENAI CONFIGURATION (if LLM_PROVIDER=openai)
# ============================================================================
# Uncomment and set your API key if using OpenAI
# OPENAI_API_KEY=your_openai_api_key_here

# ============================================================================
# TRANSLATION SETTINGS
# ============================================================================
DEFAULT_SOURCE_LANGUAGE=English
DEFAULT_TARGET_LANGUAGE=French

# Chunking configuration
MAIN_LINES_PER_CHUNK=25
MAIN_CHUNK_SIZE=1000

# API request timeout (in seconds)
REQUEST_TIMEOUT=900

# ============================================================================
# CONTEXT MANAGEMENT
# ============================================================================
# Automatically adjust context/chunk size if prompt is too large
AUTO_ADJUST_CONTEXT=true
MIN_CHUNK_SIZE=5
MAX_CHUNK_SIZE=100

# ============================================================================
# ADVANCED SETTINGS
# ============================================================================
MAX_TRANSLATION_ATTEMPTS=3
RETRY_DELAY_SECONDS=5

# ============================================================================
# SRT SUBTITLE SETTINGS
# ============================================================================
SRT_LINES_PER_BLOCK=5
SRT_MAX_CHARS_PER_BLOCK=500
